{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# VGG and Gender"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "name = 'vgg_gender'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import utilities\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  2.10.1\n",
      "GPU available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU usage:  {'current': 0, 'peak': 0}\n"
     ]
    }
   ],
   "source": [
    "# Check Tensorflow version\n",
    "print('Tensorflow version: ',tf.__version__)\n",
    "# Check if GPU is being used\n",
    "print('GPU available: ', tf.config.list_physical_devices('GPU'))\n",
    "# If a GPU is being used, check that it's not being used by another process as well\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "  print(\"GPU usage: \", tf.config.experimental.get_memory_info('GPU:0'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def process_image(path_gender, label):\n",
    "    # Desired size\n",
    "    size = 250\n",
    "    path, gender = path_gender\n",
    "    # Get the image\n",
    "    img = tf.io.read_file(path)\n",
    "    # Decode the PNG\n",
    "    img = tf.image.decode_png(img)\n",
    "    # Resize image\n",
    "    img = tf.image.resize(img, (size, size))\n",
    "    # Reshape image (this is not necessary but I do it so that I don't need to be modifying the shape in the input layer)\n",
    "    img = tf.reshape(img, [size, size, 1])\n",
    "    # Cast image to float32\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    # Normalize image\n",
    "    img = img/255.0\n",
    "\n",
    "    return (img, gender), label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_data(csv_path, images_folder_path, id_col, label_col, gender_col):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    paths = [images_folder_path + '/' + str(id) + '.png' for id in df[id_col].tolist()]\n",
    "    labels = df[label_col].tolist()\n",
    "    gender = [0 if (str(g)==\"False\" or str(g)=='FALSE') else 1 for g in df[gender_col].tolist()] # male 1, female 0\n",
    "    return paths, labels, gender"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Dataset used\n",
    "ds = 'preprocessed_r250p'\n",
    "\n",
    "# INPUT PIPELINE\n",
    "#------------------------\n",
    "# Training set\n",
    "# ------------------------\n",
    "train_paths, train_labels, train_gender = get_data( csv_path='./data/pre_processed/training/train.csv',\n",
    "                                                images_folder_path='./data/pre_processed/training/{}'.format(ds),\n",
    "                                                id_col='id',\n",
    "                                                label_col='boneage',\n",
    "                                                gender_col='male')\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(((train_paths,train_gender),train_labels)).map(process_image)\n",
    "train_dataset = train_dataset.shuffle(len(train_dataset)).batch(32)\n",
    "\n",
    "#------------------------\n",
    "#Validation set\n",
    "# ------------------------\n",
    "validation_paths, validation_labels, validation_gender = get_data(\n",
    "                                                csv_path='./data/pre_processed/validation/validation.csv',\n",
    "                                                images_folder_path='./data/pre_processed/validation/{}'.format(ds),\n",
    "                                                id_col='Image ID',\n",
    "                                                label_col='Bone Age (months)',\n",
    "                                                gender_col='male')\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices(((validation_paths,validation_gender),validation_labels)).map(process_image).batch(32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# for (img,gender), label in train_dataset:\n",
    "#     print(gender)\n",
    "#     break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instantiate the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Model for only images\n",
    "\n",
    "input_img = Input(shape=train_dataset.element_spec[0][0].shape[1:])\n",
    "x = Conv2D(8, (3,3), activation='relu', padding='same')(input_img)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(8, (3,3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2,2))(x)\n",
    "x = Conv2D(16, (3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(16, (3,3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2,2))(x)\n",
    "x = Conv2D(32, (3,3), strides=2, activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(32, (3,3), strides=2, activation='relu', padding='same' )(x)\n",
    "x = MaxPooling2D((2,2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Model(inputs=input_img,outputs=x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Gender branch\n",
    "input_gender = Input(shape=(1,))\n",
    "y = Dense(100, activation='relu')(input_gender)\n",
    "\n",
    "# Concatenate the two layers\n",
    "z = tf.keras.layers.concatenate([x.output, y])\n",
    "z = Dense(100, activation='relu')(z)\n",
    "z = Dense(100, activation='relu')(z)\n",
    "z = Dense(1)(z)\n",
    "\n",
    "model = Model(inputs=[x.input, input_gender], outputs=z)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='mse',\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError()])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# To make that the learning rate decreases\n",
    "def schedule(epoch, lr):\n",
    "    if epoch>=60:\n",
    "        return 0.0001\n",
    "    return 0.001\n",
    "scheduler = tf.keras.callbacks.LearningRateScheduler(schedule)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Experiment tracking with tensorboard\n",
    "import time\n",
    "experiment_name = \"{}_{}_{}\".format(name,ds,int(time.time()))\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='./logs/{}'.format(experiment_name))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 250, 250, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 250, 250, 8)  80          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 250, 250, 8)  32         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 250, 250, 8)  584         ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 125, 125, 8)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 125, 125, 16  1168        ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 125, 125, 16  64         ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 125, 125, 16  2320        ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 125, 125, 16  64         ['conv2d_3[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 62, 62, 16)  0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 31, 31, 32)   4640        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 31, 31, 32)  128         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 16, 16, 32)   9248        ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 32)    0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 2048)         0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          1049088     ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 512)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 100)          200         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 612)          0           ['dropout_1[0][0]',              \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 100)          61300       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 100)          10100       ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1)            101         ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,139,117\n",
      "Trainable params: 1,138,973\n",
      "Non-trainable params: 144\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training (\"fit\") the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInternalError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Fit the model\u001B[39;00m\n\u001B[0;32m      2\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3\u001B[39m  \u001B[38;5;66;03m# or any other integer value that works for your system\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx_validate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_validate\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m15\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001B[0m, in \u001B[0;36mconvert_to_eager_tensor\u001B[1;34m(value, ctx, dtype)\u001B[0m\n\u001B[0;32m    100\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtypes\u001B[38;5;241m.\u001B[39mas_dtype(dtype)\u001B[38;5;241m.\u001B[39mas_datatype_enum\n\u001B[0;32m    101\u001B[0m ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m--> 102\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEagerTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mInternalError\u001B[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/395 [==============>...............] - ETA: 22s - loss: 3861.5698 - root_mean_squared_error: 62.1415"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "r = model.fit(train_dataset, validation_data = validation_dataset, epochs=75, callbacks=[scheduler, tensorboard])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221/395 [===============>..............] - ETA: 16s - loss: 1783.6154 - root_mean_squared_error: 42.2329"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's now save our model to a file\n",
    "model.save('./models/{}.h5'.format(experiment_name))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make predictions\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p_test = model.predict(validation_dataset).reshape(-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Show some misclassified examples\n",
    "y_test = np.array([label.numpy() for (img,gender), label in validation_dataset.unbatch()])\n",
    "x_test = np.array([img.numpy() for (img,gender), label in validation_dataset.unbatch()])\n",
    "difference = np.abs(np.subtract(y_test, p_test))\n",
    "misclassified_idx = np.where(difference>45)\n",
    "#print(len(misclassified_idx[0]))\n",
    "i = np.random.choice(misclassified_idx[0])\n",
    "plt.imshow(x_test[i], cmap='gray')\n",
    "plt.title(\"True label: %s Predicted: %s\" % (y_test[i], p_test[i]));"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist, bins = np.histogram(p_test, bins=20)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(p_test, bins=bins)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist, bins = np.histogram(validation_labels, bins=20)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(validation_labels, bins=bins)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist, bins = np.histogram(train_labels, bins=20)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(train_labels, bins=bins)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

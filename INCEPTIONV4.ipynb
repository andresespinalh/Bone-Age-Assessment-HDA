{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Inception V4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "name = 'inceptionv4'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import utilities\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout, MaxPooling2D, BatchNormalization, Activation, AveragePooling2D\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check Tensorflow version\n",
    "print('Tensorflow version: ',tf.__version__)\n",
    "# Check if GPU is being used\n",
    "print('GPU available: ', tf.config.list_physical_devices('GPU'))\n",
    "# If a GPU is being used, check that it's not being used by another process as well\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "  print(\"GPU usage: \", tf.config.experimental.get_memory_info('GPU:0'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def process_image(path, label):\n",
    "    # Desired size\n",
    "    size = 250\n",
    "    # Get the image\n",
    "    img = tf.io.read_file(path)\n",
    "    # Decode the PNG\n",
    "    img = tf.image.decode_png(img)\n",
    "    # Resize image\n",
    "    img = tf.image.resize(img, (size, size))\n",
    "    # Reshape image (this is not necessary but I do it so that I don't need to be modifying the shape in the input layer)\n",
    "    img = tf.reshape(img, [size, size, 1])\n",
    "    # Cast image to float32\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    # Normalize image\n",
    "    img = img/255.0\n",
    "\n",
    "    return img, label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_paths_n_labels(csv_path, images_folder_path, id_col, label_col):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    paths = [images_folder_path + '/' + str(id) + '.png' for id in df[id_col].tolist()]\n",
    "    labels = df[label_col].tolist()\n",
    "    return paths, labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Dataset used\n",
    "ds = 'clahecropfill2_r250'\n",
    "\n",
    "# Input pipeline\n",
    "# Training set\n",
    "train_paths, train_labels = get_paths_n_labels( csv_path='./data/pre_processed/training/train.csv',\n",
    "                                                images_folder_path='./data/pre_processed/training/{}'.format(ds),\n",
    "                                                id_col='id',\n",
    "                                                label_col='boneage')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
    "train_dataset = train_dataset.map(process_image)\n",
    "train_dataset = train_dataset.shuffle(len(train_dataset)).batch(8)\n",
    "\n",
    "#Validation set\n",
    "validation_paths, validation_labels = get_paths_n_labels(\n",
    "                                                csv_path='./data/pre_processed/validation/validation/validation.csv',\n",
    "                                                images_folder_path='./data/pre_processed/validation/validation/{}'.format(ds),\n",
    "                                                id_col='Image ID',\n",
    "                                                label_col='Bone Age (months)')\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_paths, validation_labels))\n",
    "validation_dataset = validation_dataset.map(process_image).batch(8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for img, label in train_dataset:\n",
    "#     print(type(img))\n",
    "#     break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instantiate the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Useful functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#-----------------------------------------------\n",
    "# Convolution + Batch Normalization + Activation\n",
    "#-----------------------------------------------\n",
    "# conv_bn_act block\n",
    "#-----------------------------------------------\n",
    "def conv_bn_act(X_input, filters, kernel_size, strides, padding='same', activation=None, name=None):\n",
    "\n",
    "    # Add the layers\n",
    "    x = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = padding, name='conv_'+name)(X_input)\n",
    "    x  = BatchNormalization(name='bn'+name)(x)\n",
    "    if activation is not None:\n",
    "        x = Activation(activation)(x)\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inception blocks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#-----------------------------------------------\n",
    "# STEM BLOCK\n",
    "#-----------------------------------------------\n",
    "# stem_block\n",
    "#-----------------------------------------------\n",
    "def stem_block(X_input):\n",
    "\n",
    "    # First conv\n",
    "    X = conv_bn_act(X_input, filters = 32, kernel_size = (3, 3), strides = (2, 2),\n",
    "                    padding = 'valid', activation='relu', name = 'stem_1th')\n",
    "    # Second conv\n",
    "    X = conv_bn_act(X, filters = 32, kernel_size = (3, 3), strides = (1, 1),\n",
    "                    padding = 'valid', activation='relu', name = 'stem_2nd')\n",
    "    # Third conv\n",
    "    X = conv_bn_act(X, filters = 64, kernel_size = (3, 3), strides = (1, 1),\n",
    "                  padding = 'same', activation='relu', name =  'stem_3rd')\n",
    "    #-----------------------------------------------\n",
    "    # BRANCH SPLIT\n",
    "    #-----------------------------------------------\n",
    "    # First branch: max pooling\n",
    "    branch1 = MaxPooling2D(pool_size = (3, 3), strides = (2, 2),\n",
    "                           padding = 'valid', name = 'stem_1stbranch_1')(X)\n",
    "    # Second branch: conv\n",
    "    branch2 = conv_bn_act(X, filters = 96, kernel_size = (3, 3), strides = (2, 2),\n",
    "                          padding = 'valid', activation='relu', name = 'stem_1stbranch_2')\n",
    "\n",
    "    #-----------------------------------------------\n",
    "    # MERGE BRANCHES\n",
    "    #-----------------------------------------------\n",
    "    # Concatenate (1) branch1 and branch2 along the channel axis\n",
    "    X = tf.concat(values=[branch1, branch2], axis=3)\n",
    "\n",
    "    #-----------------------------------------------\n",
    "    # BRANCH SPLIT\n",
    "    #-----------------------------------------------\n",
    "    # First branch: 2 convs\n",
    "    branch1 = conv_bn_act(X, filters = 64, kernel_size = (1, 1),\n",
    "                        strides = (1, 1), padding = 'same', activation='relu',\n",
    "                        name = 'stem_2ndbranch_1_1')\n",
    "    branch1 = conv_bn_act(branch1, filters = 96, kernel_size = (3, 3),\n",
    "                        strides = (1, 1), padding = 'valid', activation='relu',\n",
    "                        name = 'stem_2ndbranch_1_2')\n",
    "\n",
    "    # Second branch: 4 convs\n",
    "    branch2 = conv_bn_act(X, filters = 64, kernel_size = (1, 1),\n",
    "                        strides = (1, 1), padding = 'same', activation='relu',\n",
    "                        name = 'stem_2ndbranch_2_1')\n",
    "    branch2 = conv_bn_act(branch2, filters = 64, kernel_size = (7, 1),\n",
    "                        strides = (1, 1), padding = 'same', activation='relu',\n",
    "                        name = 'stem_2ndbranch_2_2')\n",
    "    branch2 = conv_bn_act(branch2, filters = 64, kernel_size = (1, 7),\n",
    "                        strides = (1, 1), padding = 'same', activation='relu',\n",
    "                        name = 'stem_2ndbranch_2_3')\n",
    "    branch2 = conv_bn_act(branch2, filters = 96, kernel_size = (3, 3),\n",
    "                        strides = (1, 1), padding = 'valid', activation='relu',\n",
    "                        name = 'stem_2ndbranch_2_4')\n",
    "\n",
    "    #-----------------------------------------------\n",
    "    # MERGE BRANCHES\n",
    "    #-----------------------------------------------\n",
    "    # Concatenate (2) branch1 and branch2 along the channel axis\n",
    "    X = tf.concat(values=[branch1, branch2], axis=3)\n",
    "\n",
    "    #-----------------------------------------------\n",
    "    # BRANCH SPLIT\n",
    "    #-----------------------------------------------\n",
    "    # First branch: conv\n",
    "    branch1 = conv_bn_act(X, filters = 192, kernel_size = (3, 3), strides = (2, 2),\n",
    "                          padding = 'valid', activation='relu', name = 'stem_3rdbranch_1')\n",
    "    # Second branch: max pooling\n",
    "    branch2 = MaxPooling2D(pool_size = (3, 3), strides = (2, 2),\n",
    "                           padding = 'valid', name = 'stem_3rdbranch_2')(X)\n",
    "\n",
    "    #-----------------------------------------------\n",
    "    # MERGE BRANCHES\n",
    "    #-----------------------------------------------\n",
    "    # Concatenate (3) branch1 and branch2 along the channel axis\n",
    "    X = tf.concat(values=[branch1, branch2], axis=3)\n",
    "\n",
    "    return X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#-----------------------------------------------\n",
    "# INCEPTION A BLOCK\n",
    "#-----------------------------------------------\n",
    "# inception_a_block\n",
    "#-----------------------------------------------\n",
    "def inception_a_block(X_input, base_name):\n",
    "\n",
    "    #-----------------------------------------------\n",
    "    # BRANCH SPLIT\n",
    "    #-----------------------------------------------\n",
    "    # Branch 1\n",
    "    branch1 = AveragePooling2D(pool_size = (3, 3), strides = (1, 1),\n",
    "                               padding = 'same', name = base_name + 'ia_branch_1_1')(X_input)\n",
    "    branch1 = conv_bn_act(branch1, filters = 96, kernel_size = (1, 1), strides = (1, 1),\n",
    "                          padding = 'same', activation='relu', name = base_name + 'ia_branch_1_2')\n",
    "    # Branch 2\n",
    "    branch2 = conv_bn_act(X_input, filters = 96, kernel_size = (1, 1), strides = (1, 1),\n",
    "                          padding = 'same', activation='relu', name = base_name + 'ia_branch_2_1')\n",
    "    # Branch 3\n",
    "    branch3 = conv_bn_act(X_input, filters = 64, kernel_size = (1, 1),strides = (1, 1),\n",
    "                          padding = 'same', activation='relu', name = base_name + 'ia_branch_3_1')\n",
    "    branch3 = conv_bn_act(branch3, filters = 96, kernel_size = (3, 3), strides = (1, 1),\n",
    "                          padding = 'same', activation='relu', name = base_name + 'ia_branch_3_2')\n",
    "    # Branch 4\n",
    "    branch4 = conv_bn_act(X_input, filters = 64, kernel_size = (1, 1), strides = (1, 1),\n",
    "                          padding = 'same', activation='relu', name = base_name + 'ia_branch_4_1')\n",
    "    branch4 = conv_bn_act(branch4, filters = 96, kernel_size = (3, 3), strides = (1, 1),\n",
    "                          padding = 'same', activation='relu', name = base_name + 'ia_branch_4_2')\n",
    "    branch4 = conv_bn_act(branch4, filters = 96, kernel_size = (3, 3), strides = (1, 1),\n",
    "                          padding = 'same', activation='relu',  name = base_name + 'ia_branch_4_3')\n",
    "\n",
    "    #-----------------------------------------------\n",
    "    # MERGE BRANCHES\n",
    "    #-----------------------------------------------\n",
    "    # Concatenate branch1, branch2, branch3 and branch4 along the channel axis\n",
    "    X = tf.concat(values=[branch1, branch2, branch3, branch4], axis=3)\n",
    "\n",
    "    return X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#-----------------------------------------------\n",
    "# INCEPTION B BLOCK\n",
    "#-----------------------------------------------\n",
    "# inception_b_block\n",
    "#-----------------------------------------------\n",
    "def inception_b_block(X_input, base_name):\n",
    "\n",
    "    #-----------------------------------------------\n",
    "    # BRANCH SPLIT\n",
    "    #-----------------------------------------------\n",
    "    # Branch 1\n",
    "    branch1 = AveragePooling2D(pool_size = (3, 3), strides = (1, 1),\n",
    "                           padding = 'same', name = base_name + 'ib_branch_1_1')(X_input)\n",
    "    branch1 = conv_bn_act(branch1, filters = 128, kernel_size = (1, 1),\n",
    "                        strides = (1, 1), padding = 'same', activation='relu',\n",
    "                        name = base_name + 'ib_branch_1_2')\n",
    "    # Branch 2\n",
    "    branch2 = conv_bn_act(X_input, filters = 384, kernel_size = (1, 1),\n",
    "                        strides = (1, 1), padding = 'same', activation='relu',\n",
    "                        name = base_name + 'ib_branch_2_1')\n",
    "    # Branch 3\n",
    "    branch3 = conv_bn_act(X_input, filters = 192, kernel_size = (1, 1), strides = (1, 1),\n",
    "                          padding = 'same', activation='relu', name = base_name + 'ib_branch_3_1')\n",
    "    branch3 = conv_bn_act(branch3, filters = 224, kernel_size = (1, 7), strides = (1, 1),\n",
    "                          padding = 'same', activation='relu', name = base_name + 'ib_branch_3_2')\n",
    "    branch3 = conv_bn_act(branch3, filters = 256, kernel_size = (7, 1), strides = (1, 1),\n",
    "                          padding = 'same', activation='relu', name = base_name + 'ib_branch_3_3')\n",
    "\n",
    "    # Branch 4\n",
    "    branch4 = conv_bn_act(X_input, filters = 192, kernel_size = (1, 1),\n",
    "                        strides = (1, 1), padding = 'same', activation='relu',\n",
    "                        name = base_name + 'ib_branch_4_1')\n",
    "    branch4 = conv_bn_act(branch4, filters = 192, kernel_size = (1, 7),\n",
    "                        strides = (1, 1), padding = 'same', activation='relu',\n",
    "                        name = base_name + 'ib_branch_4_2')\n",
    "    branch4 = conv_bn_act(branch4, filters = 224, kernel_size = (7, 1),\n",
    "                        strides = (1, 1), padding = 'same', activation='relu',\n",
    "                        name = base_name + 'ib_branch_4_3')\n",
    "    branch4 = conv_bn_act(branch4, filters = 224, kernel_size = (1, 7),\n",
    "                        strides = (1, 1), padding = 'same', activation='relu',\n",
    "                        name = base_name + 'ib_branch_4_4')\n",
    "    branch4 = conv_bn_act(branch4, filters = 256, kernel_size = (7, 1),\n",
    "                        strides = (1, 1), padding = 'same', activation='relu',\n",
    "                        name = base_name + 'ib_branch_4_5')\n",
    "\n",
    "    #-----------------------------------------------\n",
    "    # MERGE BRANCHES\n",
    "    #-----------------------------------------------\n",
    "    # Concatenate branch1, branch2, branch3 and branch4 along the channel axis\n",
    "    X = tf.concat(values=[branch1, branch2, branch3, branch4], axis=3)\n",
    "\n",
    "    return X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#-----------------------------------------------\n",
    "# INCEPTION C BLOCK\n",
    "#-----------------------------------------------\n",
    "# inception_c_block\n",
    "#-----------------------------------------------\n",
    "def inception_c_block(X_input, base_name):\n",
    "\n",
    "    #-----------------------------------------------\n",
    "    # BRANCH SPLIT\n",
    "    #-----------------------------------------------\n",
    "\n",
    "    # Branch 1\n",
    "    branch1 = AveragePooling2D(pool_size = (3, 3), strides = (1, 1),\n",
    "                           padding = 'same', name = base_name + 'ic_branch_1_1')(X_input)\n",
    "    branch1 = conv_bn_act(branch1, filters = 256, kernel_size = (1, 1), strides = (1, 1),\n",
    "                          padding = 'same', activation='relu', name = base_name + 'ic_branch_1_2')\n",
    "\n",
    "    # Branch 2\n",
    "    branch2 = conv_bn_act(X_input, filters = 256, kernel_size = (1, 1), strides = (1, 1),\n",
    "                          padding = 'same', activation='relu', name = base_name + 'ic_branch_2_1')\n",
    "\n",
    "    # Branch 3\n",
    "    branch3 = conv_bn_act(X_input, filters = 384, kernel_size = (1, 1), strides = (1, 1),\n",
    "                          padding = 'same', activation='relu', name = base_name + 'ic_branch_3_1')\n",
    "    branch3_1 = conv_bn_act(branch3, filters = 256, kernel_size = (1, 3), strides = (1, 1),\n",
    "                            padding = 'same', activation='relu', name = base_name + 'ic_branch_3_2')\n",
    "    branch3_2 = conv_bn_act(branch3, filters = 256, kernel_size = (3, 1), strides = (1, 1),\n",
    "                            padding = 'same', activation='relu', name = base_name + 'ic_branch_3_3')\n",
    "\n",
    "    # Branch 4\n",
    "    branch4 = conv_bn_act(X_input, filters = 384, kernel_size = (1, 1), strides = (1, 1),\n",
    "                          padding = 'same', activation='relu', name = base_name + 'ic_branch_4_1')\n",
    "    branch4 = conv_bn_act(branch4, filters = 448, kernel_size = (1, 3), strides = (1, 1),\n",
    "                          padding = 'same', activation='relu', name = base_name + 'ic_branch_4_2')\n",
    "    branch4 = conv_bn_act(branch4, filters = 512, kernel_size = (3, 1), strides = (1, 1),\n",
    "                          padding = 'same', activation='relu', name = base_name + 'ic_branch_4_3')\n",
    "    branch4_1 = conv_bn_act(branch4, filters = 256, kernel_size = (3, 1), strides = (1, 1),\n",
    "                          padding = 'same', activation='relu', name = base_name + 'ic_branch_4_4')\n",
    "    branch4_2 = conv_bn_act(branch4, filters = 256, kernel_size = (1, 3), strides = (1, 1),\n",
    "                            padding = 'same', activation='relu', name = base_name + 'ic_branch_4_5')\n",
    "\n",
    "    #-----------------------------------------------\n",
    "    # MERGE BRANCHES\n",
    "    #-----------------------------------------------\n",
    "    # Concatenate branch1, branch2, branch3_1, branch3_2, branch4_1 and branch4_2 along the channel axis\n",
    "    X = tf.concat(values=[branch1, branch2, branch3_1, branch3_2, branch4_1, branch4_2], axis=3)\n",
    "\n",
    "    return X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#-----------------------------------------------\n",
    "# REDUCTION A BLOCK\n",
    "#-----------------------------------------------\n",
    "# reduction_a_block\n",
    "#-----------------------------------------------\n",
    "def reduction_a_block(X_input):\n",
    "    #-----------------------------------------------\n",
    "    # BRANCH SPLIT\n",
    "    #-----------------------------------------------\n",
    "    # Branch 1\n",
    "    branch1 = MaxPooling2D(pool_size = (3, 3), strides = (2, 2),\n",
    "                           padding = 'valid', name = 'ra_branch_1_1')(X_input)\n",
    "    # Branch 2\n",
    "    branch2 = conv_bn_act(X_input, filters = 384, kernel_size = (3, 3), strides = (2, 2),\n",
    "                          padding = 'valid', activation='relu', name = 'ra_branch_2_1')\n",
    "    # Branch 3\n",
    "    branch3 = conv_bn_act(X_input, filters = 192, kernel_size = (1, 1), strides = (1, 1),\n",
    "                          padding = 'same', activation='relu', name = 'ra_branch_3_1')\n",
    "    branch3 = conv_bn_act(branch3, filters = 224, kernel_size = (3, 3), strides = (1, 1),\n",
    "                          padding = 'same', activation='relu', name = 'ra_branch_3_2')\n",
    "    branch3 = conv_bn_act(branch3, filters = 256, kernel_size = (3, 3), strides = (2, 2),\n",
    "                          padding = 'valid', activation='relu',name = 'ra_branch_3_3')\n",
    "\n",
    "    #-----------------------------------------------\n",
    "    # MERGE BRANCHES\n",
    "    #-----------------------------------------------\n",
    "    # Concatenate branch1, branch2 and branch3 along the channel axis\n",
    "    X = tf.concat(values=[branch1, branch2, branch3], axis=3)\n",
    "\n",
    "    return X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#-----------------------------------------------\n",
    "# REDUCTION B BLOCK\n",
    "#-----------------------------------------------\n",
    "# reduction_b_block\n",
    "#-----------------------------------------------\n",
    "def reduction_b_block(X_input):\n",
    "    #-----------------------------------------------\n",
    "    # BRANCH SPLIT\n",
    "    #-----------------------------------------------\n",
    "    # Branch 1\n",
    "    branch1 = MaxPooling2D(pool_size = (3, 3), strides = (2, 2),\n",
    "                           padding = 'valid', name = 'rb_branch_1_1')(X_input)\n",
    "\n",
    "    # Branch 2\n",
    "    branch2 = conv_bn_act(X_input, filters = 192, kernel_size = (1, 1), strides = (1, 1),\n",
    "                          padding = 'same', activation='relu', name = 'rb_branch_2_1')\n",
    "    branch2 = conv_bn_act(branch2, filters = 192, kernel_size = (3, 3), strides = (2, 2),\n",
    "                          padding = 'valid', activation='relu', name = 'rb_branch_2_2')\n",
    "\n",
    "    # Branch 3\n",
    "    branch3 = conv_bn_act(X_input, filters = 256, kernel_size = (1, 1), strides = (1, 1),\n",
    "                          padding = 'same', activation='relu', name = 'rb_branch_3_1')\n",
    "    branch3 = conv_bn_act(branch3, filters = 256, kernel_size = (1, 7), strides = (1, 1),\n",
    "                          padding = 'same', activation='relu', name = 'rb_branch_3_2')\n",
    "    branch3 = conv_bn_act(branch3, filters = 320, kernel_size = (7, 1), strides = (1, 1),\n",
    "                          padding = 'same', activation='relu', name = 'rb_branch_3_3')\n",
    "    branch3 = conv_bn_act(branch3, filters = 320, kernel_size = (3, 3), strides = (2, 2),\n",
    "                          padding = 'valid', activation='relu', name = 'rb_branch_3_4')\n",
    "\n",
    "    #-----------------------------------------------\n",
    "    # MERGE BRANCHES\n",
    "    #-----------------------------------------------\n",
    "    # Concatenate branch1, branch2 and branch3 along the channel axis\n",
    "    X = tf.concat(values=[branch1, branch2, branch3], axis=3)\n",
    "\n",
    "    return X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Network construction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# FUNCTION: Inception-v4\n",
    "\n",
    "def Inceptionv4(input_shape):\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape (1 line)\n",
    "    X_input = Input(shape=input_shape)\n",
    "\n",
    "    # Call the above functions for the stem, inception-a, reduction-a, inception-b, reduction-b and inception-c blocks\n",
    "    X = stem_block(X_input)\n",
    "\n",
    "    # Four Inception A blocks\n",
    "    X = inception_a_block(X, 'a1')\n",
    "    X = inception_a_block(X, 'a2')\n",
    "    X = inception_a_block(X, 'a3')\n",
    "    X = inception_a_block(X, 'a4')\n",
    "\n",
    "    # Reduction A block\n",
    "    X = reduction_a_block(X)\n",
    "\n",
    "    # Seven Inception B blocks\n",
    "    X = inception_b_block(X, 'b1')\n",
    "    X = inception_b_block(X, 'b2')\n",
    "    X = inception_b_block(X, 'b3')\n",
    "    X = inception_b_block(X, 'b4')\n",
    "    X = inception_b_block(X, 'b5')\n",
    "    X = inception_b_block(X, 'b6')\n",
    "    X = inception_b_block(X, 'b7')\n",
    "\n",
    "    # Reduction B block\n",
    "    X = reduction_b_block(X)\n",
    "\n",
    "    # Three Inception C blocks\n",
    "    X = inception_c_block(X, 'c1')\n",
    "    X = inception_c_block(X, 'c2')\n",
    "    X = inception_c_block(X, 'c3')\n",
    "\n",
    "    # AVGPOOL (1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    kernel_pooling = X.get_shape()[1:3]\n",
    "    X = AveragePooling2D(kernel_pooling, name='avg_pool')(X)\n",
    "    X = Flatten()(X)\n",
    "\n",
    "    # Dropout\n",
    "    X = Dropout(rate = 0.2)(X)\n",
    "\n",
    "    # Output layer\n",
    "    X = Dense(1, name='linear')(X)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='Inceptionv4')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Inceptionv4(input_shape = (250, 250, 1))\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mse',\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError()])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Experiment tracking with tensorboard\n",
    "import time\n",
    "experiment_name = \"{}_{}_{}\".format(name,ds,int(time.time()))\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='./logs/{}'.format(experiment_name))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training (\"fit\") the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInternalError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Fit the model\u001B[39;00m\n\u001B[0;32m      2\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3\u001B[39m  \u001B[38;5;66;03m# or any other integer value that works for your system\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx_validate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_validate\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m15\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001B[0m, in \u001B[0;36mconvert_to_eager_tensor\u001B[1;34m(value, ctx, dtype)\u001B[0m\n\u001B[0;32m    100\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtypes\u001B[38;5;241m.\u001B[39mas_dtype(dtype)\u001B[38;5;241m.\u001B[39mas_datatype_enum\n\u001B[0;32m    101\u001B[0m ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m--> 102\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEagerTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mInternalError\u001B[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/395 [==============>...............] - ETA: 22s - loss: 3861.5698 - root_mean_squared_error: 62.1415"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "r = model.fit(train_dataset, validation_data=validation_dataset, epochs=100, callbacks=[tensorboard])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's now save our model to a file\n",
    "model.save('./models/{}.h5'.format(experiment_name))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = tf.keras.models.load_model('./models/{}.h5'.format(experiment_name))\n",
    "model.evaluate(validation_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p_test = model.predict(validation_dataset).reshape(-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Show some misclassified examples\n",
    "y_test = np.array([y.numpy() for x, y in validation_dataset.unbatch()])\n",
    "x_test = np.array([x.numpy() for x, y in validation_dataset.unbatch()])\n",
    "difference = np.abs(np.subtract(y_test, p_test))\n",
    "misclassified_idx = np.where(difference<4)\n",
    "#print(misclassified_idx)\n",
    "i = np.random.choice(misclassified_idx[0])\n",
    "plt.imshow(x_test[i], cmap='gray')\n",
    "plt.title(\"True label: %s Predicted: %s\" % (y_test[i], p_test[i]));"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
